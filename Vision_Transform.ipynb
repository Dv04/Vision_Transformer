{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gLEEms7wilZP"
      },
      "outputs": [],
      "source": [
        "                                                                                                                                                                                                                                                                                              # Cell 1: Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import layers, regularizers\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import gc\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import (\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Conv2D,\n",
        "    Reshape,\n",
        "    Input,\n",
        ")\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cy2Vdrh-Skmg"
      },
      "outputs": [],
      "source": [
        "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "# print(physical_devices)\n",
        "# if physical_devices:\n",
        "#   tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-0RQGoVXmk-s"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Define Constants and Custom Loss\n",
        "HEIGHT = 64\n",
        "WIDTH = 64\n",
        "\n",
        "def weighted_mse(yTrue, yPred):\n",
        "    ones = K.ones_like(yTrue[0, :])\n",
        "    idx = K.cumsum(ones)\n",
        "    return K.mean((1 / idx) * K.square(yTrue - yPred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aJzI0RyWmpq9"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Image Manipulation Functions\n",
        "\n",
        "# rotate image by a given angle\n",
        "def rotateImage(image, angle):\n",
        "    (h, w) = image.shape[:2]\n",
        "    (cX, cY) = (w // 2, h // 2)\n",
        "\n",
        "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
        "    cos = np.abs(M[0, 0])\n",
        "    sin = np.abs(M[0, 1])\n",
        "\n",
        "    nW = int((h * sin) + (w * cos))\n",
        "    nH = int((h * cos) + (w * sin))\n",
        "\n",
        "    M[0, 2] += (nW / 2) - cX\n",
        "    M[1, 2] += (nH / 2) - cY\n",
        "\n",
        "    return cv2.warpAffine(image, M, (nW, nH))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZs0KN37muAj",
        "outputId": "023ff037-f46e-46da-93d1-7299a000cdad"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Data Split Function\n",
        "def splitter(train_ratio,validation_ratio):\n",
        "\n",
        "    data=[]\n",
        "    folders = glob.glob('/content/drive/MyDrive/PetImages/*') # Path to folder containing images\n",
        "    for image_class in folders:\n",
        "        # print(image_class)\n",
        "        for image in os.listdir(os.path.join(image_class)):\n",
        "            X=[]\n",
        "            X.append(os.path.join(image_class,image));\n",
        "            X.append(image_class.split('/')[-1])\n",
        "            data.append(X)\n",
        "    # # Split into train, validation, and test sets\n",
        "    data=pd.Series(data)\n",
        "    data=data.sample(frac=1) #randomizes the data array.\n",
        "    train_size=int(train_ratio*len(data))\n",
        "    train_files = data[0:train_size]\n",
        "    validation_size=int(validation_ratio*len(train_files))\n",
        "    validation_files = train_files[:validation_size]\n",
        "    test_files = data[train_size:]\n",
        "\n",
        "\n",
        "    # train_pca = []\n",
        "\n",
        "    print(folders)\n",
        "    print(len(train_files))\n",
        "    print(len(validation_files))\n",
        "    print(len(test_files))\n",
        "    return train_files, test_files, validation_files\n",
        "\n",
        "train_files, test_files, validation_files = splitter(train_ratio=0.7,validation_ratio=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApGQYvobSkmj"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "FnfAn8F8mz-3",
        "outputId": "c079c05e-48d5-4f48-8713-5a93df466db1"
      },
      "outputs": [],
      "source": [
        "# Cell 5: PCA Function\n",
        "def PCA_Done(train_files):\n",
        "    data = np.zeros((len(train_files), 201))\n",
        "\n",
        "    # for i, file in enumerate(train_files):\n",
        "    #     label_name = # Get Labels\n",
        "\n",
        "    # using the training files fit pca\n",
        "    pca = PCA(n_components=20)\n",
        "    pca.fit(data)\n",
        "    explained_var = pca.explained_variance_ratio_\n",
        "    print(explained_var)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(range(len(explained_var)), explained_var, alpha=0.5, align='center', label='individual explained variance')\n",
        "    plt.step(range(len(explained_var)), np.cumsum(explained_var), where='mid', label='cumulative explained variance')\n",
        "    plt.xlabel('Principal components')\n",
        "    plt.ylabel('Explained variance ratio')\n",
        "    plt.legend(loc='best')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(sum(pca.explained_variance_ratio_))\n",
        "    # print(pca)\n",
        "    return pca\n",
        "pca = PCA_Done(train_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yYao4150m4t_"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Batch Generator\n",
        "def batch_generator(pca, X, batch_size=64):\n",
        "    while True:\n",
        "        # Select files (paths/indices) for the batch\n",
        "        batch_paths = np.random.randint(low=0, high=len(X), size=batch_size)\n",
        "\n",
        "        images = []\n",
        "        props = []\n",
        "        batch_label = []\n",
        "\n",
        "        # Read in each input, perform preprocessing and get labels\n",
        "\n",
        "        for index in batch_paths:\n",
        "            img=cv2.imread(X[index][0])\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img=cv2.resize(img,(64,64))\n",
        "            img=img/255.0\n",
        "            images.append(img)\n",
        "            batch_label.append(X[index][1])\n",
        "\n",
        "        # For Each file in the batch:\n",
        "            # Add code for generating images and labels here.\n",
        "            # First read the image as grayscale\n",
        "            # Then resize the image to 64x64\n",
        "            # Then normalize the image\n",
        "            # Then reshape the image to (64,64,1)\n",
        "            # Then append the image to the images list\n",
        "            # Then read the corresponding label file\n",
        "            # Then append the label to the labels list\n",
        "\n",
        "\n",
        "        batch_x = np.array(images)\n",
        "        batch_y = np.array(batch_label)\n",
        "\n",
        "        yield (batch_x, batch_y)\n",
        "\n",
        "train_gen = batch_generator(pca, train_files)\n",
        "valid_gen = batch_generator(pca, validation_files, batch_size=8)\n",
        "test_gen = batch_generator(pca, test_files, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UiYR72Gm-nu"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Model Building Function\n",
        "def build_vit_model(image_size, num_classes, num_heads=4, num_transformer_layers=4):\n",
        "    inputs = layers.Input(shape=(image_size, image_size, 3))\n",
        "    # Convert image to patches\n",
        "    patches = layers.Conv2D(filters=64, kernel_size=(8, 8), strides=(8, 8))(inputs)\n",
        "    patches = layers.Reshape((64, 64))(patches)\n",
        "    # Add Dropout\n",
        "    patches = layers.Dropout(0.2)(patches)\n",
        "\n",
        "    # Positional encoding\n",
        "    pos_enc = layers.Embedding(input_dim=64, output_dim=64)(\n",
        "        tf.range(start=0, limit=64, delta=1)\n",
        "    )\n",
        "    patches += pos_enc\n",
        "\n",
        "    # Transformer layers\n",
        "    for _ in range(num_transformer_layers):\n",
        "        # Multi-head attention\n",
        "        attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=64)(\n",
        "            patches, patches\n",
        "        )\n",
        "        patches = layers.LayerNormalization()(patches + attn_output)\n",
        "\n",
        "        # Feed-forward network\n",
        "        ffn = layers.Dense(128, activation=\"relu\")(patches)\n",
        "        ffn = layers.Dense(64)(ffn)\n",
        "        # add dropout\n",
        "        ffn = layers.Dropout(0.2)(ffn)\n",
        "\n",
        "        patches = layers.LayerNormalization()(patches)\n",
        "\n",
        "\n",
        "\n",
        "    output = layers.Dense(20, activation=\"linear\")(patches[:, 0, :])\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "model = build_vit_model(64, 1)  # Replace 256 with your actual image size\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
        "    loss=weighted_mse,\n",
        "    metrics=[\"mae\"],\n",
        ")\n",
        "print(model.summary())\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        \"Best_Model.h5\", save_weights_only=True, save_best_only=True, mode=\"min\"\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.8,\n",
        "        patience=100,\n",
        "        min_lr=1e-5,\n",
        "        min_delta=0.000001,\n",
        "        verbose=1,\n",
        "        mode=\"min\",\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z30l9LOeSkml"
      },
      "outputs": [],
      "source": [
        "\n",
        "# CODE FOR HYPERPARAMETERS TUNING\n",
        "\n",
        "# from kerastuner.tuners import RandomSearch\n",
        "\n",
        "# def build_model(hp):\n",
        "#     model = build_vit_model(\n",
        "#         image_size=hp.Int('image_size', min_value=32, max_value=256, step=32),\n",
        "#         num_classes=10,\n",
        "#         num_heads=hp.Int('num_heads', min_value=2, max_value=8, step=2),\n",
        "#         num_transformer_layers=hp.Int('num_transformer_layers', min_value=1, max_value=8, step=1)\n",
        "#     )\n",
        "#     model.compile(optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
        "#                   loss='sparse_categorical_crossentropy',\n",
        "#                   metrics=['accuracy'])\n",
        "#     return model\n",
        "\n",
        "# tuner = RandomSearch(\n",
        "#     build_model,\n",
        "#     objective='val_accuracy',\n",
        "#     max_trials=5,  # number of different hyperparameter configurations to try\n",
        "#     executions_per_trial=3,  # number of times to train each model, to average out the metrics\n",
        "#     directory='random_search',\n",
        "#     project_name='vit'\n",
        "# )\n",
        "\n",
        "# tuner.search(train_gen, epochs=5, validation_data=(valid_gen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tgu9BUJaSkml"
      },
      "outputs": [],
      "source": [
        "# best_model = tuner.get_best_models(num_models=1)[0]\n",
        "# best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JipzOOBInHUX"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Prediction Function\n",
        "def predict():\n",
        "    for file in test_files[:25]:\n",
        "        img = cv2.imread(file, 0)\n",
        "\n",
        "        folder = os.path.split(os.path.split(file)[0])[1]\n",
        "\n",
        "        # Image processing should be done here\n",
        "\n",
        "\n",
        "        # Get Properties\n",
        "\n",
        "        # Concatenate Image and Properties\n",
        "        # img = np.concatenate((img, props), axis=2)\n",
        "        # img = img.reshape(-1, img.shape[0], img.shape[1], img.shape[2])\n",
        "\n",
        "        # Get Labels\n",
        "\n",
        "        pred = model.predict(img)\n",
        "        predictions = pca.inverse_transform(pred).reshape(-1)\n",
        "\n",
        "        # label_file[\"pred_values\"] = predictions\n",
        "        # print(label_file[\"pred_values\"].shape)\n",
        "        # plt.ylim(0,0.1)\n",
        "        # plt.plot(predictions)\n",
        "        # plt.plot(label)\n",
        "        # plt.legend([\"Predictions\", \"Actual_Values\"])\n",
        "        # plt.show()\n",
        "\n",
        "K.clear_session()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sphiHpMonKom"
      },
      "outputs": [],
      "source": [
        "# model.load_weights('best_model_v2.h5')\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=1500,\n",
        "    verbose=1,\n",
        "    batch_size=32,\n",
        "    validation_data=valid_gen,\n",
        "    validation_steps=len(validation_files) // 8,\n",
        "    steps_per_epoch=len(train_files) // 32,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "model.save_weights('Final_Model_weights.h5')\n",
        "\n",
        "model.save('Final_Model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bcg55ioESkmm"
      },
      "outputs": [],
      "source": [
        "# plot training and validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75cwquIqaNtE"
      },
      "outputs": [],
      "source": [
        "model.load_weights('Iteration_1_model.h5')\n",
        "print(f\"Test Loss: {model.evaluate(test_gen, steps=len(test_files))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gow1fkC-WeeJ"
      },
      "outputs": [],
      "source": [
        "predict()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
