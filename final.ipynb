{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cab5cc4-1f73-4afd-aaac-05205682cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0746b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 0.   GLOBAL SETTINGS – adjust if your paths differ\n",
    "###############################################################################\n",
    "IMG_H, IMG_W = 64, 64  # image size (matches saved model)\n",
    "PATCH_SIZE = 8  # kept for ViT inference only\n",
    "PCA_NCOMP = 20  # must match training\n",
    "BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 8\n",
    "DATA_DIR = \"data\"  # root folder for images + CSV\n",
    "VIT_H5_PATH = \"iteration_5_model.h5\"  # saved full model (inc. weights)\n",
    "RESULT_DIR = \"paper_results\"  # all outputs land here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3fc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1.   IMPORTS\n",
    "###############################################################################\n",
    "import os, glob, re, gc, cv2, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, regularizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Conv2D,\n",
    "    Reshape,\n",
    "    Input,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Cell 1: Import Libraries\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc3081",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 2.   HELPERS  (splitter, augmentation, PCA, batch-gen) – 100 % compatible\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def rotate_img(im, angle):\n",
    "    (h, w) = im.shape[:2]\n",
    "    cX, cY = w // 2, h // 2\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "    cos, sin = np.abs(M[0, 0]), np.abs(M[0, 1])\n",
    "    nW, nH = int((h * sin) + (w * cos)), int((h * cos) + (w * sin))\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "    return cv2.warpAffine(im, M, (nW, nH))\n",
    "\n",
    "\n",
    "def weighted_mse(yTrue, yPred):\n",
    "    # create a monotonically increasing weight vector\n",
    "    ones = tf.ones_like(yTrue[0, :])\n",
    "    idx = tf.math.cumsum(ones, axis=0)\n",
    "    # apply weighted MSE\n",
    "    loss = tf.reduce_mean((1.0 / tf.cast(idx, tf.float32)) * tf.square(yTrue - yPred))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def collect_files():\n",
    "    train, val, test = [], [], []\n",
    "    for folder in glob.glob(f\"{DATA_DIR}/*\"):\n",
    "        for fname in os.listdir(folder):\n",
    "            if not fname.endswith(\".jpg\"):\n",
    "                continue\n",
    "            csv_path = os.path.join(folder, fname.replace(\".jpg\", \".csv\"))\n",
    "            if not os.path.exists(csv_path):\n",
    "                continue\n",
    "            try:\n",
    "                row_count = pd.read_csv(csv_path).shape[0]\n",
    "                if row_count != 205:\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {csv_path}: {e}\")\n",
    "                continue\n",
    "            prob = random.random()\n",
    "            fpath = os.path.join(folder, fname)\n",
    "            if prob < 0.02:\n",
    "                test.append(fpath)\n",
    "            elif prob < 0.12:\n",
    "                val.append(fpath)\n",
    "            else:\n",
    "                train.append(fpath)\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "def fit_pca(jpg_list):\n",
    "    X = np.zeros((len(jpg_list), 201))\n",
    "    for i, f in enumerate(jpg_list):\n",
    "        arr = pd.read_csv(\n",
    "            f.replace(\".jpg\", \".csv\"), skiprows=range(5), names=[\"f\", \"v\"]\n",
    "        )[\"v\"].values.astype(float)\n",
    "        X[i, :] = arr\n",
    "    pca = PCA(n_components=PCA_NCOMP).fit(X)\n",
    "    # quick diagnostic bar-plot\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.bar(range(PCA_NCOMP), pca.explained_variance_ratio_)\n",
    "    plt.step(range(PCA_NCOMP), np.cumsum(pca.explained_variance_ratio_), where=\"mid\")\n",
    "    plt.title(\"PCA explained variance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULT_DIR}/pca_variance.png\", dpi=200)\n",
    "    plt.close()\n",
    "    return pca\n",
    "\n",
    "\n",
    "def preprocess_one(img_path, pca=None, augment=True):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    folder = os.path.basename(os.path.dirname(img_path))\n",
    "    if augment and folder in [\"0d65h\", \"0d75h\"]:\n",
    "        img = rotate_img(img, random.randint(0, 359))\n",
    "    img = cv2.resize(img, (IMG_W, IMG_H)) / 255.0\n",
    "    img = img.reshape(IMG_H, IMG_W, 1)\n",
    "\n",
    "    prop = [int(x) for x in re.findall(r\"\\d+\", folder)]\n",
    "    prop = np.array([prop[0] / 60, prop[1] / 75])  # normalised\n",
    "    p1, p2 = np.full((IMG_H, IMG_W, 1), prop[0]), np.full((IMG_H, IMG_W, 1), prop[1])\n",
    "    img = np.concatenate([img, p1, p2], axis=-1)\n",
    "\n",
    "    label = pd.read_csv(\n",
    "        img_path.replace(\".jpg\", \".csv\"), skiprows=range(5), names=[\"f\", \"v\"]\n",
    "    )[\"v\"].values\n",
    "    if pca is not None:\n",
    "        label = pca.transform(label.reshape(1, -1)).ravel()\n",
    "    return img.astype(\"float32\"), label.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 3.   DATA LOADING\n",
    "###############################################################################\n",
    "train_files, val_files, test_files = collect_files()\n",
    "print(f\"files: train={len(train_files)}  val={len(val_files)}  test={len(test_files)}\")\n",
    "\n",
    "pca = fit_pca(train_files)  # PCA fitted on training set ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be4768",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 4.   ViT – load reused weights (NO re-training)\n",
    "###############################################################################\n",
    "def build_vit_model(image_size, num_heads=4, num_transformer_layers=4):\n",
    "    inputs = layers.Input(shape=(image_size, image_size, 3))\n",
    "    patch_size = PATCH_SIZE\n",
    "    num_patches = (image_size // patch_size) ** 2\n",
    "    patch_dim = 64\n",
    "    patches = layers.Conv2D(\n",
    "        filters=patch_dim,\n",
    "        kernel_size=(patch_size, patch_size),\n",
    "        strides=(patch_size, patch_size),\n",
    "    )(inputs)\n",
    "    patches = layers.Reshape((num_patches, patch_dim))(patches)\n",
    "    pos_enc = layers.Embedding(input_dim=num_patches, output_dim=patch_dim)(\n",
    "        tf.range(start=0, limit=num_patches, delta=1)\n",
    "    )\n",
    "    patches = patches + pos_enc\n",
    "    for _ in range(num_transformer_layers):\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(patches)\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=patch_dim)(\n",
    "            x, x\n",
    "        )\n",
    "        x = layers.Add()([x, attn_output])\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        ffn = layers.Dense(128, activation=\"relu\")(x)\n",
    "        ffn = layers.Dense(patch_dim)(ffn)\n",
    "        patches = layers.Add()([x, ffn])\n",
    "    aggregated = layers.GlobalAveragePooling1D()(patches)\n",
    "    output = layers.Dense(PCA_NCOMP, activation=\"linear\")(aggregated)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "vit_model = build_vit_model(IMG_H, num_heads=4, num_transformer_layers=4)\n",
    "vit_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=weighted_mse, metrics=[\"mae\"])\n",
    "vit_model.load_weights(\"iteration_5_weights.h5\")\n",
    "vit_model.summary()\n",
    "\n",
    "\n",
    "def evaluate_model(model, files, name):\n",
    "    ys, preds = [], []\n",
    "    for f in files:\n",
    "        x, y = preprocess_one(f, pca=pca, augment=False)\n",
    "        pred = model.predict(x[None, ...], verbose=1)[0]\n",
    "        y_full, pred_full = (\n",
    "            pca.inverse_transform(y[None, ...])[0],\n",
    "            pca.inverse_transform(pred[None, ...])[0],\n",
    "        )\n",
    "        ys.append(y_full)\n",
    "        preds.append(pred_full)\n",
    "    mse = np.mean([mean_squared_error(y_, p_) for y_, p_ in zip(ys, preds)])\n",
    "    print(f\"{name}  MSE={mse:.5f}\")\n",
    "    return mse, ys, preds\n",
    "\n",
    "\n",
    "vit_mse, vit_y, vit_pred = evaluate_model(vit_model, test_files, \"ViT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 5.   BASELINES – CNN & MLP  (trained from scratch)\n",
    "###############################################################################\n",
    "def build_cnn():\n",
    "    i = layers.Input(shape=(IMG_H, IMG_W, 3))\n",
    "    x = layers.Conv2D(16, 3, activation=\"relu\")(i)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    o = layers.Dense(PCA_NCOMP)(x)\n",
    "    return keras.Model(i, o)\n",
    "\n",
    "\n",
    "def build_mlp():\n",
    "    i = layers.Input(shape=(IMG_H, IMG_W, 3))\n",
    "    x = layers.Flatten()(i)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    o = layers.Dense(PCA_NCOMP)(x)\n",
    "    return keras.Model(i, o)\n",
    "\n",
    "\n",
    "def make_dataset(file_list, shuffle=True):\n",
    "    def gen():\n",
    "        for f in file_list:\n",
    "            x, y = preprocess_one(f, pca=pca)\n",
    "            yield x, y\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec((IMG_H, IMG_W, 3), tf.float32),\n",
    "            tf.TensorSpec((PCA_NCOMP,), tf.float32),\n",
    "        ),\n",
    "    )\n",
    "    if shuffle:\n",
    "        print(f\"Shuffling {len(file_list)} samples (this may take a moment)…\")\n",
    "        ds = ds.shuffle(len(file_list)).repeat()\n",
    "        # after you call shuffle().repeat(), you can immediately prefetch:\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    print(\"Dataset ready—entering training loop.\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_files)\n",
    "val_ds = make_dataset(val_files, shuffle=False)\n",
    "test_ds = make_dataset(test_files, shuffle=False)\n",
    "\n",
    "\n",
    "def train_baseline(build_fn, name):\n",
    "    print(f\"\\n=== Starting {name} training ===\")\n",
    "    model = build_fn()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3), loss=weighted_mse, metrics=[\"mae\"]\n",
    "    )\n",
    "    cbs = [keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)]\n",
    "    def _on_epoch_end(epoch, logs):\n",
    "        loss = logs.get(\"loss\", float(\"nan\"))\n",
    "        val_loss = logs.get(\"val_loss\")\n",
    "        if val_loss is not None:\n",
    "            print(f\"[{name}] Epoch {epoch+1} end: loss={loss:.4f}, val_loss={val_loss:.4f}\")\n",
    "        else:\n",
    "            print(f\"[{name}] Epoch {epoch+1} end: loss={loss:.4f}\")\n",
    "\n",
    "    \n",
    "    epoch_logger = LambdaCallback(\n",
    "        on_epoch_begin=lambda epoch, logs: print(f\"[{name}] Epoch {epoch+1} start\"),\n",
    "        on_epoch_end=_on_epoch_end\n",
    "    )\n",
    "    all_cbs = cbs + [epoch_logger]\n",
    "    steps_per_epoch  = len(train_files)    // BATCH_SIZE\n",
    "    validation_steps = len(val_files)      // VAL_BATCH_SIZE\n",
    "    h = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=500,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=all_cbs,\n",
    "        verbose=1    )\n",
    "    \n",
    "    # Save history safely even if arrays differ in length\n",
    "    hist = h.history\n",
    "    # Convert each metric list to a pandas Series so shorter lists are padded with NaN\n",
    "    df_hist = pd.DataFrame({k: pd.Series(v) for k, v in hist.items()})\n",
    "    df_hist.to_csv(f\"{RESULT_DIR}/{name}_learning_curve.csv\", index=False)\n",
    "    \n",
    "    mse, ys, preds = evaluate_model(model, test_files, name)\n",
    "    model.save(f\"{RESULT_DIR}/{name}.h5\")\n",
    "    # plot learning curve\n",
    "    plt.plot(h.history[\"loss\"], label=\"train\")\n",
    "    plt.plot(h.history[\"val_loss\"], label=\"val\")\n",
    "    plt.title(f\"{name} loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULT_DIR}/{name}_curve.png\", dpi=200)\n",
    "    plt.close()\n",
    "    return mse, ys, preds\n",
    "\n",
    "\n",
    "cnn_mse, cnn_y, cnn_pred = train_baseline(build_cnn, \"CNN\")\n",
    "mlp_mse, mlp_y, mlp_pred = train_baseline(build_mlp, \"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 6.   RESULTS TABLE  (for paper)\n",
    "###############################################################################\n",
    "tbl = pd.DataFrame(\n",
    "    {\"Model\": [\"ViT\", \"CNN\", \"MLP\"], \"Test_MSE\": [vit_mse, cnn_mse, mlp_mse]}\n",
    ")\n",
    "tbl.to_csv(f\"{RESULT_DIR}/model_comparison.csv\", index=False)\n",
    "print(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e6839",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 7.   SPECTRA OVERLAYS  (first 4 test samples for each model)\n",
    "###############################################################################\n",
    "def plot_spec(y_true, y_pred, tag, idx):\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.plot(y_true, label=\"FEM\")\n",
    "    plt.plot(y_pred, label=tag, ls=\"--\")\n",
    "    plt.title(f\"Sample {idx} – {tag}\")\n",
    "    plt.ylabel(\"Absorption\")\n",
    "    plt.xlabel(\"Freq idx\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULT_DIR}/{tag}_spec_{idx}.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "for i in range(min(4, len(test_files))):\n",
    "    plot_spec(vit_y[i], vit_pred[i], \"ViT\", i)\n",
    "    plot_spec(cnn_y[i], cnn_pred[i], \"CNN\", i)\n",
    "    plot_spec(mlp_y[i], mlp_pred[i], \"MLP\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 8.   DATASET STATISTICS  (bins + augmentation count)\n",
    "###############################################################################\n",
    "def get_props(f):\n",
    "    folder = os.path.basename(os.path.dirname(f))\n",
    "    h, a = [int(x) for x in re.findall(r\"\\d+\", folder)]\n",
    "    return h, a\n",
    "\n",
    "\n",
    "stats = pd.DataFrame(\n",
    "    [get_props(f) for f in train_files + val_files + test_files],\n",
    "    columns=[\"height_mm\", \"angle_deg\"],\n",
    ")\n",
    "stats[\"split\"] = (\n",
    "    [\"train\"] * len(train_files) + [\"val\"] * len(val_files) + [\"test\"] * len(test_files)\n",
    ")\n",
    "stats.to_csv(f\"{RESULT_DIR}/dataset_stats.csv\", index=False)\n",
    "\n",
    "print(\"\\nAll artifacts are in:\", RESULT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
