{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6f1e30-ea25-47f8-8626-3f11a619ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2ed5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 17:30:31.506260: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-26 17:30:31.573971: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-26 17:30:31.576403: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-26 17:30:32.361264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ## 0.  Install & Imports\n",
    "# (Uncomment if running fresh environment)\n",
    "# !pip install tensorflow==2.19.0 scikit-learn opencv-python matplotlib pandas\n",
    "\n",
    "import os, re, glob, cv2, gc\n",
    "import numpy as np, pandas as pd, tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f9777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ## 1.  Configuration\n",
    "\n",
    "# Paths\n",
    "DATA_DIR        = Path(\"data\")             # expects subfolders of .jpg/.csv\n",
    "OUTPUT_DIR      = Path(\"outputs/notebook\") \n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Image & PCA\n",
    "IMG_H = IMG_W = 64\n",
    "PCA_NCOMP = 20\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE      = 64\n",
    "EPOCHS          = 5\n",
    "BASE_LR         = 3e-4\n",
    "PATIENCE        = 50\n",
    "\n",
    "# ViT architecture\n",
    "PATCH_SIZE      = 8\n",
    "VIT_NUM_HEADS   = 6\n",
    "VIT_LAYERS      = 6\n",
    "MLP_DIM         = 128\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 42123\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9062a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ## 2.  Helper Functions\n",
    "\n",
    "def natural_sort(filelist):\n",
    "    \"\"\"Sort file paths in human order.\"\"\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', str(key)) ]\n",
    "    return sorted(filelist, key=alphanum_key)\n",
    "\n",
    "def collect_images():\n",
    "    jpgs = list(DATA_DIR.glob(\"*/*.jpg\"))\n",
    "    return natural_sort(jpgs)\n",
    "\n",
    "def split_files(jpg_list):\n",
    "    \"\"\"Deterministic split: train/val/test.\"\"\"\n",
    "    n = len(jpg_list)\n",
    "    n_test = int(0.02 * n)\n",
    "    n_val  = int(0.10 * n)\n",
    "    test   = jpg_list[:n_test]\n",
    "    val    = jpg_list[n_test:n_test+n_val]\n",
    "    train  = jpg_list[n_test+n_val:]\n",
    "    return train, val, test\n",
    "\n",
    "def load_spectrum(path):\n",
    "    \"\"\"Read .csv, skip first 5 lines, return float32 spectrum.\"\"\"\n",
    "    arr = pd.read_csv(path, skiprows=range(5), names=[\"f\",\"v\"])[\"v\"].to_numpy(dtype=\"float32\")\n",
    "    return arr\n",
    "\n",
    "def fit_pca(train_paths):\n",
    "    # gather only spectra of consistent length\n",
    "    spectra_list = []\n",
    "    expected_len = None\n",
    "    for p in train_paths:\n",
    "        arr = load_spectrum(p.with_suffix(\".csv\"))\n",
    "        if expected_len is None:\n",
    "            expected_len = arr.shape[0]\n",
    "        if arr.shape[0] != expected_len:\n",
    "            print(f\"Skipping {p.name}: length {arr.shape[0]} (expected {expected_len})\")\n",
    "            continue\n",
    "        spectra_list.append(arr)\n",
    "    if not spectra_list:\n",
    "        raise ValueError(\"No valid spectra found for PCA. Check CSV files for row consistency.\")\n",
    "    spectra = np.stack(spectra_list)    \n",
    "    pca = PCA(n_components=PCA_NCOMP, random_state=SEED).fit(spectra)\n",
    "    return pca\n",
    "\n",
    "def parse_one(path, pca, augment=True):\n",
    "    \"\"\"Load JPG + CSV, apply optional rotation, pack props into channels.\"\"\"\n",
    "    # load grayscale image\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)\n",
    "    folder = path.parent.name\n",
    "\n",
    "    # augment: random rotation for specific folders\n",
    "    if augment and folder in {\"0d65h\",\"0d75h\"}:\n",
    "        angle = np.random.randint(0,360)\n",
    "        M = cv2.getRotationMatrix2D((IMG_W/2, IMG_H/2), angle, 1.0)\n",
    "        img = cv2.warpAffine(img, M, (IMG_W, IMG_H), borderMode=cv2.BORDER_REFLECT)\n",
    "    else:\n",
    "        img = cv2.resize(img, (IMG_W, IMG_H))\n",
    "\n",
    "    # normalize\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    img = img[...,None]  # shape (H,W,1)\n",
    "\n",
    "    # extract numeric properties from folder name, map to [0,1]\n",
    "    h,a = [int(x) for x in re.findall(r\"\\d+\", folder)]\n",
    "    prop = np.array([h/60., a/75.], dtype=\"float32\")\n",
    "    prop1 = np.full((IMG_H, IMG_W, 1), prop[0], dtype=\"float32\")\n",
    "    prop2 = np.full((IMG_H, IMG_W, 1), prop[1], dtype=\"float32\")\n",
    "    img = np.concatenate([img, prop1, prop2], axis=-1)  # shape (H,W,3)\n",
    "\n",
    "    # PCA-transform the spectrum\n",
    "    spectrum = load_spectrum(path.with_suffix(\".csv\"))\n",
    "    y = pca.transform(spectrum.reshape(1,-1))[0].astype(\"float32\")\n",
    "    return img, y\n",
    "\n",
    "def make_tf_dataset(paths, pca, training=False):\n",
    "    \"\"\"Build a tf.data.Dataset for a list of Paths.\"\"\"\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    def gen():\n",
    "        expected_dim = pca.components_.shape[1]\n",
    "        for p in paths:\n",
    "            spec = load_spectrum(p.with_suffix(\".csv\"))\n",
    "            if spec.shape[0] != expected_dim:\n",
    "                print(f\"Skipping {p.name}: spectrum length {spec.shape[0]} ≠ expected {expected_dim}\")\n",
    "                continue\n",
    "            yield parse_one(p, pca, augment=training)\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec((IMG_H, IMG_W, 3), tf.float32),\n",
    "            tf.TensorSpec((PCA_NCOMP,), tf.float32),\n",
    "        )\n",
    "    )\n",
    "    if training:\n",
    "        ds = ds.shuffle(len(paths), seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    idx = tf.cast(tf.range(1, PCA_NCOMP+1), tf.float32)\n",
    "    return tf.reduce_mean((1.0/idx) * tf.square(y_true - y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a2ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ## 3.  Build the Vision Transformer\n",
    "\n",
    "def patch_embed(x):\n",
    "    x = layers.Conv2D(filters=MLP_DIM,\n",
    "                      kernel_size=(PATCH_SIZE,PATCH_SIZE),\n",
    "                      strides=(PATCH_SIZE,PATCH_SIZE),\n",
    "                      padding=\"valid\")(x)\n",
    "    num_patches = (IMG_H//PATCH_SIZE)**2\n",
    "    x = layers.Reshape((num_patches, MLP_DIM))(x)\n",
    "    return x\n",
    "\n",
    "def build_vit():\n",
    "    inp = layers.Input((IMG_H, IMG_W, 3))\n",
    "    x   = patch_embed(inp)\n",
    "\n",
    "    # learnable positional embedding\n",
    "    pos = layers.Embedding(input_dim=x.shape[1], output_dim=MLP_DIM)(\n",
    "        tf.range(start=0, limit=x.shape[1], delta=1)\n",
    "    )\n",
    "    x = x + pos\n",
    "\n",
    "    # transformer encoder blocks\n",
    "    for _ in range(VIT_LAYERS):\n",
    "        # attention block\n",
    "        y = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        y = layers.MultiHeadAttention(\n",
    "            num_heads=VIT_NUM_HEADS, key_dim=MLP_DIM\n",
    "        )(y, y)\n",
    "        x = layers.Add()([x, y])\n",
    "\n",
    "        # MLP block\n",
    "        y = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        y = layers.Dense(MLP_DIM*4, activation=\"gelu\")(y)\n",
    "        y = layers.Dense(MLP_DIM)(y)\n",
    "        x = layers.Add()([x, y])\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    out = layers.Dense(PCA_NCOMP, activation=\"linear\")(x)\n",
    "    return keras.Model(inputs=inp, outputs=out, name=\"ViT_PCA\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f917daf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: train=2976  val=338  test=67\n",
      "Skipping 30d75h-178.jpg: length 21 (expected 201)\n",
      "Skipping 60d75h-897.jpg: length 0 (expected 201)\n",
      "PCA fitted, explained variance sum: 0.96804994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 17:30:36.936420: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ## 4.  Prepare Data & PCA\n",
    "\n",
    "all_jpg = collect_images()\n",
    "train_files, val_files, test_files = split_files(all_jpg)\n",
    "print(f\"Splits: train={len(train_files)}  val={len(val_files)}  test={len(test_files)}\")\n",
    "\n",
    "pca = fit_pca(train_files)\n",
    "print(\"PCA fitted, explained variance sum:\", pca.explained_variance_ratio_.sum())\n",
    "\n",
    "train_ds = make_tf_dataset(train_files, pca, training=True)\n",
    "val_ds   = make_tf_dataset(val_files,   pca, training=False)\n",
    "test_ds  = make_tf_dataset(test_files,  pca, training=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da596deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ViT_PCA\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 8, 8, 128)            24704     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 64, 128)              0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 64, 128)              0         ['reshape[0][0]']             \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 64, 128)              256       ['tf.__operators__.add[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 64, 128)              395648    ['layer_normalization[0][0]', \n",
      " iHeadAttention)                                                     'layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 64, 128)              0         ['tf.__operators__.add[0][0]',\n",
      "                                                                     'multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 64, 128)              256       ['add[0][0]']                 \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64, 512)              66048     ['layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 64, 128)              65664     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 64, 128)              0         ['add[0][0]',                 \n",
      "                                                                     'dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 64, 128)              256       ['add_1[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 64, 128)              395648    ['layer_normalization_2[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 64, 128)              0         ['add_1[0][0]',               \n",
      "                                                                     'multi_head_attention_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 64, 128)              256       ['add_2[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 64, 512)              66048     ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 64, 128)              65664     ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 64, 128)              0         ['add_2[0][0]',               \n",
      "                                                                     'dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 64, 128)              256       ['add_3[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, 64, 128)              395648    ['layer_normalization_4[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 64, 128)              0         ['add_3[0][0]',               \n",
      "                                                                     'multi_head_attention_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 64, 128)              256       ['add_4[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 64, 512)              66048     ['layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 64, 128)              65664     ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 64, 128)              0         ['add_4[0][0]',               \n",
      "                                                                     'dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 64, 128)              256       ['add_5[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 64, 128)              395648    ['layer_normalization_6[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 64, 128)              0         ['add_5[0][0]',               \n",
      "                                                                     'multi_head_attention_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 64, 128)              256       ['add_6[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 64, 512)              66048     ['layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 64, 128)              65664     ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 64, 128)              0         ['add_6[0][0]',               \n",
      "                                                                     'dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (None, 64, 128)              256       ['add_7[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, 64, 128)              395648    ['layer_normalization_8[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 64, 128)              0         ['add_7[0][0]',               \n",
      "                                                                     'multi_head_attention_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (None, 64, 128)              256       ['add_8[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 64, 512)              66048     ['layer_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 64, 128)              65664     ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 64, 128)              0         ['add_8[0][0]',               \n",
      "                                                                     'dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, 64, 128)              256       ['add_9[0][0]']               \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, 64, 128)              395648    ['layer_normalization_10[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 64, 128)              0         ['add_9[0][0]',               \n",
      "                                                                     'multi_head_attention_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, 64, 128)              256       ['add_10[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 64, 512)              66048     ['layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 64, 128)              65664     ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 64, 128)              0         ['add_10[0][0]',              \n",
      "                                                                     'dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 128)                  0         ['add_11[0][0]']              \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 20)                   2580      ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3194516 (12.19 MB)\n",
      "Trainable params: 3194516 (12.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "Skipping 30d75h-178.jpg: spectrum length 21 ≠ expected 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 17:30:56.070864: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 2552 of 2976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 60d75h-897.jpg: spectrum length 0 ≠ expected 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 17:30:57.710043: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     43/Unknown - 60s 926ms/step - loss: 0.2647 - mae: 0.6874"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ## 5.  Compile & Train\n",
    "\n",
    "strategy = tf.distribute.get_strategy()  # change if multi-GPU\n",
    "with strategy.scope():\n",
    "    model = build_vit()\n",
    "    opt = tf.keras.optimizers.Adam(BASE_LR)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=weighted_mse,\n",
    "                  metrics=[\"mae\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=PATIENCE//2, factor=0.5),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        str(OUTPUT_DIR/\"vit_best.h5\"), save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.TensorBoard(str(OUTPUT_DIR/\"tb\")),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "pd.DataFrame(history.history).to_csv(OUTPUT_DIR/\"history.csv\", index=False)\n",
    "model.save(OUTPUT_DIR/\"vit_final.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15405f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ## 6.  Evaluate on Test Set\n",
    "\n",
    "mse_list = []\n",
    "for x_batch, y_batch in test_ds:\n",
    "    preds = model.predict(x_batch, verbose=1)\n",
    "    mses = np.mean((y_batch - preds)**2, axis=1)\n",
    "    mse_list.extend(mses.tolist())\n",
    "\n",
    "print(\"Mean Test MSE:\", np.mean(mse_list))\n",
    "\n",
    "# plot a few spectra overlays\n",
    "import matplotlib.pyplot as plt\n",
    "count=0\n",
    "for x_batch, y_batch in test_ds.take(1):\n",
    "    preds = model.predict(x_batch, verbose=1)\n",
    "    inv_true = pca.inverse_transform(y_batch)\n",
    "    inv_pred = pca.inverse_transform(preds)\n",
    "    for i in range(min(31, len(inv_true))):\n",
    "        plt.figure()\n",
    "        plt.plot(inv_true[i], label=\"True\")\n",
    "        plt.plot(inv_pred[i], '--', label=\"Pred\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"Sample {count}\")\n",
    "        plt.ylim(0, 1)  \n",
    "        plt.show()\n",
    "        count+=1\n",
    "\n",
    "# %%\n",
    "print(\"Notebook run complete! All artefacts in\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e624bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.0571WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "38/38 [==============================] - 27s 433ms/step - loss: 0.0571\n",
      "  Fold 4 MSE=0.01031, 7.47 ms/sample\n",
      "\n",
      "▶ Fold 5/5\n",
      "Epoch 1/2\n",
      "     38/Unknown - 33s 465ms/step - loss: 0.2129WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "38/38 [==============================] - 33s 466ms/step - loss: 0.2129\n",
      "Epoch 2/2\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0565WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "38/38 [==============================] - 26s 424ms/step - loss: 0.0565\n",
      "Skipping 30d75h-178.jpg: spectrum length 21 ≠ expected 201\n",
      "Skipping 60d75h-897.jpg: spectrum length 0 ≠ expected 201\n",
      "  Skipping 30d75h-178.jpg: X has 21 features, but PCA is expecting 201 features as input.\n",
      "  Skipping 60d75h-897.jpg: Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required by PCA.\n",
      "  Fold 5 MSE=0.00973, 7.60 ms/sample\n",
      "✅ K-fold summary written to outputs/notebook/vit_kfold.json \n",
      " {'mse_mean': 0.009577682241797447, 'mse_std': 0.0007598736556246877, 'avg_ms_per_sample': 6.664649968166674}\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 7: 5-FOLD CROSS-VALIDATION (C-2), with per-sample validation\n",
    "from sklearn.model_selection import KFold\n",
    "import json, time\n",
    "\n",
    "def kfold_vit(build_fn, all_files, k=5, epochs=EPOCHS):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "    mses, times = [], []\n",
    "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(all_files), 1):\n",
    "        print(f\"\\n▶ Fold {fold}/{k}\")\n",
    "        tr = [all_files[i] for i in tr_idx]\n",
    "        vl = [all_files[i] for i in vl_idx]\n",
    "\n",
    "        ds_tr = make_tf_dataset(tr, pca, training=True)\n",
    "        ds_vl = make_tf_dataset(vl, pca, training=False)\n",
    "\n",
    "        # build & train\n",
    "        m = build_fn()\n",
    "        m.compile(optimizer=keras.optimizers.Adam(BASE_LR),\n",
    "                  loss=weighted_mse)\n",
    "        m.fit(ds_tr,\n",
    "              epochs=epochs,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=PATIENCE,\n",
    "                                                       restore_best_weights=True)],\n",
    "              verbose=1)\n",
    "\n",
    "        # measure inference-time\n",
    "        t0 = time.perf_counter()\n",
    "        _  = m.predict(ds_vl, verbose=0)\n",
    "        t1 = time.perf_counter()\n",
    "        sec_sample = (t1 - t0) / len(vl)\n",
    "\n",
    "        # evaluate MSE on each valid sample\n",
    "        ys, preds = [], []\n",
    "        for p in vl:\n",
    "            try:\n",
    "                x,y = parse_one(p, pca, augment=False)\n",
    "            except ValueError as e:\n",
    "                print(f\"  Skipping {p.name}: {e}\")\n",
    "                continue\n",
    "            pr = m.predict(x[None,...], verbose=0)[0]\n",
    "            ys.append(pca.inverse_transform(y[None,:])[0])\n",
    "            preds.append(pca.inverse_transform(pr[None,:])[0])\n",
    "\n",
    "        if not ys:\n",
    "            print(f\"  No valid samples in fold {fold}, skipping metrics.\")\n",
    "            continue\n",
    "\n",
    "        fold_mse = np.mean([mean_squared_error(a,b) for a,b in zip(ys,preds)])\n",
    "        print(f\"  Fold {fold} MSE={fold_mse:.5f}, {sec_sample*1000:.2f} ms/sample\")\n",
    "        mses.append(fold_mse); times.append(sec_sample)\n",
    "\n",
    "        tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "    summary = {\n",
    "        \"mse_mean\": float(np.mean(mses)),\n",
    "        \"mse_std\":  float(np.std(mses)),\n",
    "        \"avg_ms_per_sample\": float(np.mean(times))*1000\n",
    "    }\n",
    "    with open(OUTPUT_DIR/\"vit_kfold.json\",\"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(\"✅ K-fold summary written to\", OUTPUT_DIR/\"vit_kfold.json\", \"\\n\", summary)\n",
    "\n",
    "# run it\n",
    "kfold_vit(build_vit, train_files, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 8: OUT-OF-DISTRIBUTION EVALUATION (C-3), skipping bad files\n",
    "def is_ood(path, h_min=68, h_max=72, max_angle=50):\n",
    "    h,a = [int(x) for x in re.findall(r\"\\d+\", path.parent.name)]\n",
    "    return (h < h_min or h > h_max) or (a >= max_angle)\n",
    "\n",
    "ood_files = [p for p in train_files+val_files+test_files if is_ood(p)]\n",
    "print(f\"OOD candidate set size: {len(ood_files)}\")\n",
    "\n",
    "ys, preds = [], []\n",
    "for p in ood_files:\n",
    "    try:\n",
    "        x,y = parse_one(p, pca, augment=False)\n",
    "    except ValueError as e:\n",
    "        print(f\"  Skipping {p.name}: {e}\")\n",
    "        continue\n",
    "    pr = model.predict(x[None,...], verbose=0)[0]\n",
    "    ys.append(pca.inverse_transform(y[None,:])[0])\n",
    "    preds.append(pca.inverse_transform(pr[None,:])[0])\n",
    "\n",
    "if ys:\n",
    "    ood_mse = np.mean([mean_squared_error(a,b) for a,b in zip(ys,preds)])\n",
    "    print(f\"✅ ViT OOD MSE = {ood_mse:.5f}\")\n",
    "    pd.DataFrame({\n",
    "        \"file\": [p.name for p in ood_files[:len(ys)]],\n",
    "        \"mse\":  [mean_squared_error(a,b) for a,b in zip(ys,preds)]\n",
    "    }).to_csv(OUTPUT_DIR/\"vit_ood_details.csv\", index=False)\n",
    "else:\n",
    "    print(\"⚠️  No valid OOD samples found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Inverse-Design (improved)\n",
    "import tensorflow as tf\n",
    "\n",
    "def inverse_design_constrained(target_csv, steps=300, lr=1e-1, tv_weight=1e-2):\n",
    "    # 1. load & PCA-project target spectrum\n",
    "    spec   = load_spectrum(Path(target_csv))\n",
    "    if spec.shape[0] != pca.n_features_in_:\n",
    "        raise ValueError(\"CSV length mismatch\")\n",
    "    t_pca  = pca.transform(spec.reshape(1,-1))[0]\n",
    "\n",
    "    # 2. build initial guess: start from a uniform gray geometry\n",
    "    #    and freeze channels 1 & 2 to the known physical props\n",
    "    #    parse_one() can give us prop-channels for one sample:\n",
    "    example_img, _ = parse_one(train_files[0], pca, augment=False)\n",
    "    prop1 = example_img[...,1:2]  # channel 1\n",
    "    prop2 = example_img[...,2:3]  # channel 2\n",
    "\n",
    "    # trainable geometry channel (1): initialize to 0.5\n",
    "    geom = tf.Variable(tf.ones([1,IMG_H,IMG_W,1]) * 0.5, dtype=tf.float32)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr)\n",
    "    best_l, best_geom = 1e9, None\n",
    "\n",
    "    for step in range(1, steps+1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # assemble full input: [geom, prop1, prop2]\n",
    "            x = tf.concat([geom, prop1[None,...], prop2[None,...]], axis=-1)\n",
    "            pred = model(x, training=False)                   # ViT forward\n",
    "            err  = tf.reduce_mean((pred - t_pca)**2)          # spectrum MSE\n",
    "\n",
    "            # total variation loss on geometry for smoothness\n",
    "            tv   = tf.image.total_variation(geom)[0]\n",
    "            loss = err + tv_weight * tv\n",
    "\n",
    "        grads = tape.gradient(loss, [geom])\n",
    "        opt.apply_gradients(zip(grads, [geom]))\n",
    "        # clamp geometry to [0,1]\n",
    "        geom.assign(tf.clip_by_value(geom, 0.0, 1.0))\n",
    "\n",
    "        # track best\n",
    "        if loss < best_l:\n",
    "            best_l, best_geom = float(loss), geom.numpy().copy()\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f\"step {step:>3d}  err={err:.4e}  tv={tv:.4e}\")\n",
    "\n",
    "    # 3. threshold geometry to binary mask\n",
    "    bin_geom = (best_geom[0,...,0] > 0.5).astype(np.uint8) * 255\n",
    "    out_png = OUTPUT_DIR/f\"inv_design_bin_{Path(target_csv).stem}.png\"\n",
    "    cv2.imwrite(str(out_png), bin_geom)\n",
    "\n",
    "    # 4. export the predicted spectrum\n",
    "    full_input = np.stack([bin_geom/255, \n",
    "                           prop1[...,:,0], \n",
    "                           prop2[...,:,0]], axis=-1)[None,...]\n",
    "    pred_pca   = model(full_input, training=False)[0].numpy()\n",
    "    pred_spec  = pca.inverse_transform(pred_pca)\n",
    "    pd.DataFrame({\"target\":spec, \"predicted\":pred_spec})\\\n",
    "      .to_csv(OUTPUT_DIR/f\"inv_design_{Path(target_csv).stem}_spec.csv\", index=False)\n",
    "\n",
    "    print(f\"Saved binary design → {out_png}  (best loss {best_l:.4e})\")\n",
    "    return out_png\n",
    "\n",
    "# Example usage:\n",
    "# inverse_design_constrained(\"data/0d65h/sample_123.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
